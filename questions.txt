1. What are the assumptions of linear regression?

    Linearity: The relationship between input variables and output is linear.
    Independence: Observations are independent.
    Homoscedasticity: Constant variance of residuals.
    Normality: Residuals follow a normal distribution.
    No multicollinearity: Predictors aren’t highly correlated with each other.


2. When should you use logistic regression instead of linear regression?
-> Use logistic regression when the target variable is categorical, especially binary (e.g. 0/1, yes/no). Linear regression isn’t suitable for predicting probabilities or class labels.

3. What is the interpretation of coefficients in logistic regression?
-> Each coefficient represents the change in log-odds of the outcome for a one-unit increase in the predictor, keeping others constant. Positive values increase odds, negative values decrease odds.

4. What is the difference between sigmoid and softmax functions?

    Sigmoid maps values to a probability between 0 and 1, used in binary classification.
    Softmax generalizes sigmoid for multiclass classification, converting logits into probabilities that sum to 1 across classes.

5. Why is R-squared not suitable for evaluating logistic regression models?
-> R² measures variance in continuous outcomes. Logistic regression predicts class probabilities, not continuous values, so metrics like accuracy, F1-score, and AUC are more appropriate.